{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fb5af0",
   "metadata": {},
   "source": [
    "# Augmented Test to SQL Grammar Parser\n",
    "Uses an augmented context free grammar (CFG) to parse natural language queries into SQL queries to search the Air Traffic Information Systems (ATIS) database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08ccc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from cryptography.fernet import Fernet\n",
    "import copy\n",
    "import datetime\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import wget\n",
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext.legacy as tt\n",
    "from cryptography.fernet import Fernet\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f5c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "# Set timeout for executing SQL\n",
    "TIMEOUT = 3 # seconds\n",
    "\n",
    "# GPU check: Set runtime type to use GPU where available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db471636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 16404480 / 16404480"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data//atis_sqlite (1).db'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download needed scripts and data\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('scripts', exist_ok=True)\n",
    "source_url = \"https://raw.githubusercontent.com/nlp-course/data/master\"\n",
    "\n",
    "# Grammar to augment\n",
    "if not os.path.isfile('data/grammar'):\n",
    "  wget.download(f\"{source_url}/ATIS/grammar_distrib4.crypt\", out=\"data/\")\n",
    "\n",
    "  # Decrypt the grammar file\n",
    "  key = b'bfksTY2BJ5VKKK9xZb1PDDLaGkdu7KCDFYfVePSEfGY='\n",
    "  fernet = Fernet(key)\n",
    "  with open('./data/grammar_distrib4.crypt', 'rb') as f:\n",
    "    restored = Fernet(key).decrypt(f.read())\n",
    "  with open('./data/grammar', 'wb') as f:\n",
    "    f.write(restored)\n",
    "\n",
    "# Download scripts and ATIS database\n",
    "wget.download(f\"{source_url}/scripts/trees/transform.py\", out=\"scripts/\")\n",
    "wget.download(f\"{source_url}/ATIS/atis_sqlite.db\", out=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d42237e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downloaded scripts for parsing augmented grammars\n",
    "sys.path.insert(1, './scripts')\n",
    "import transform as xform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfe302",
   "metadata": {},
   "source": [
    "Making grammar specific convenience functions for augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1336dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant(value):\n",
    "  \"\"\"Return `value`, ignoring any arguments\"\"\"\n",
    "  return lambda *args: value\n",
    "\n",
    "def first(*args):\n",
    "  \"\"\"Return the value of the first (and perhaps only) subconstituent, \n",
    "     ignoring any others\"\"\"  \n",
    "  return args[0]\n",
    "\n",
    "def numeric_template(rhs):\n",
    "  \"\"\"Ignore the subphrase meanings and lookup the first right-hand-side symbol \n",
    "     as a number\"\"\"\n",
    "  return constant({'zero':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5,\n",
    "          'six':6, 'seven':7, 'eight':8, 'nine':9, 'ten':10}[rhs[0]])\n",
    "\n",
    "def forward(F, A):\n",
    "  \"\"\"Forward application: Return the application of the first \n",
    "     argument to the second\"\"\"\n",
    "  return F(A)\n",
    "\n",
    "def backward(A, F):\n",
    "  \"\"\"Backward application: Return the application of the second \n",
    "     argument to the first\"\"\"\n",
    "  return F(A)\n",
    "\n",
    "def second(*args):\n",
    "  \"\"\"Return the value of the second subconstituent, ignoring any others\"\"\"\n",
    "  return args[1]\n",
    "\n",
    "def ignore(*args):\n",
    "  \"\"\"Return `None`, ignoring everything about the constituent. (Good as a\n",
    "     placeholder until a better augmentation can be devised.)\"\"\"\n",
    "  return None\n",
    "\n",
    "def upper(term):\n",
    "  return '\"' + term.upper() + '\"'\n",
    "\n",
    "def weekday(day):\n",
    "  return f\"flight.flight_days IN (SELECT days.days_code FROM days WHERE days.day_name = '{day.upper()}')\"\n",
    "\n",
    "def month_name(month):\n",
    "  return {'JANUARY' : 1,\n",
    "          'FEBRUARY' : 2,\n",
    "          'MARCH' : 3,\n",
    "          'APRIL' : 4,\n",
    "          'MAY' : 5,\n",
    "          'JUNE' : 6,\n",
    "          'JULY' : 7,\n",
    "          'AUGUST' : 8,\n",
    "          'SEPTEMBER' : 9,\n",
    "          'OCTOBER' : 10,\n",
    "          'NOVEMBER' : 11,\n",
    "          'DECEMBER' : 12}[month.upper()]\n",
    "\n",
    "def airports_from_airport_name(airport_name):\n",
    "  return f\"(SELECT airport.airport_code FROM airport WHERE airport.airport_name = {upper(airport_name)})\"\n",
    "\n",
    "def airports_from_city(city):\n",
    "  return f\"\"\"\n",
    "    (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN\n",
    "      (SELECT city.city_code FROM city WHERE city.city_name = {upper(city)}))\n",
    "  \"\"\"\n",
    "\n",
    "def null_condition(*args, **kwargs):\n",
    "  return 1\n",
    "\n",
    "def depart_around(time):\n",
    "  return f\"\"\"\n",
    "    flight.departure_time >= {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    AND flight.departure_time <= {add_delta(miltime(time), 15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def arrive_around(time):\n",
    "  return f\"\"\"\n",
    "    flight.arrival_time >= {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    AND flight.arrival_time <= {add_delta(miltime(time), 15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def arrive_before(time):\n",
    "  return f\"\"\"\n",
    "    flight.arrival_time < {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def arrive_after(time):\n",
    "  return f\"\"\"\n",
    "    flight.arrival_time > {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def arrive(time):\n",
    "  return f\"\"\"\n",
    "    flight.arrival_time = {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def depart_before(time):\n",
    "  return f\"\"\"\n",
    "    flight.departure_time <= {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def depart_after(time):\n",
    "  return f\"\"\"\n",
    "    flight.departure_time < {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def depart(time):\n",
    "  return f\"\"\"\n",
    "    flight.departure_time = {add_delta(miltime(time), -15).strftime('%H%M')}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def add_delta(tme, delta):\n",
    "    # transform to a full datetime first\n",
    "    return (datetime.datetime.combine(datetime.date.today(), tme) + \n",
    "            datetime.timedelta(minutes=delta)).time()\n",
    "\n",
    "def miltime(minutes):\n",
    "  return datetime.time(hour=int(minutes/100), minute=(minutes % 100))\n",
    "\n",
    "\n",
    "def s_node(NP):\n",
    "  return f'SELECT DISTINCT flight.flight_id FROM flight WHERE {NP}'\n",
    "\n",
    "def to_airport(place):\n",
    "  return f'flight.to_airport IN {place}'\n",
    "\n",
    "def from_airport(place):\n",
    "  return f'flight.from_airport IN {place}'\n",
    "\n",
    "def between_airports(origin, destination):\n",
    "  return f'flight.from_airport IN {origin} AND flight.to_airport IN {destination}'\n",
    "\n",
    "def conjoin(A,B):\n",
    "  return f'{B} AND {A}'\n",
    "\n",
    "def conjoin_forward(A, B):\n",
    "  return f'{A} AND {B}'\n",
    "\n",
    "def airline_code(airline):\n",
    "  return f\"flight.airline_code = '{airline}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bb90f",
   "metadata": {},
   "source": [
    "Load and preprocess the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3463a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................] 2591248 / 2591248"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data//train_flightid (1).sql'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire the datasets - training, development, and test splits of the \n",
    "# ATIS queries and corresponding SQL queries\n",
    "wget.download(f\"{source_url}/ATIS/test_flightid.nl\", out=\"data/\")\n",
    "wget.download(f\"{source_url}/ATIS/test_flightid.sql\", out=\"data/\")\n",
    "wget.download(f\"{source_url}/ATIS/dev_flightid.nl\", out=\"data/\")\n",
    "wget.download(f\"{source_url}/ATIS/dev_flightid.sql\", out=\"data/\")\n",
    "wget.download(f\"{source_url}/ATIS/train_flightid.nl\", out=\"data/\")\n",
    "wget.download(f\"{source_url}/ATIS/train_flightid.sql\", out=\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc538b47",
   "metadata": {},
   "source": [
    "Use torchtext to process the data, with field SRC for the natural language questions and TGT for the SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca3542bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\d+|st\\.|[\\w-]+|\\$[\\d\\.]+|\\S+')\n",
    "def tokenize(string):\n",
    "  return tokenizer.tokenize(string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66f6204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = tt.data.Field(include_lengths=True,         # include lengths\n",
    "                    batch_first=False,            # batches will be max_len x batch_size\n",
    "                    tokenize=tokenize,            # use our tokenizer\n",
    "                   ) \n",
    "TGT = tt.data.Field(include_lengths=False,\n",
    "                    batch_first=False,            # batches will be max_len x batch_size\n",
    "                    tokenize=lambda x: x.split(), # use split to tokenize\n",
    "                    init_token=\"<bos>\",           # prepend <bos>\n",
    "                    eos_token=\"<eos>\")            # append <eos>\n",
    "fields = [('src', SRC), ('tgt', TGT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b5fd551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of English vocab: 421\n",
      "Most common English words: [('to', 3478), ('from', 3019), ('flights', 2094), ('the', 1550), ('on', 1230), ('me', 973), ('flight', 972), ('show', 845), ('what', 833), ('boston', 813)]\n",
      "\n",
      "Size of SQL vocab: 392\n",
      "Most common SQL words: [('=', 38876), ('AND', 36564), (',', 22772), ('airport_service', 8314), ('city', 8313), ('(', 6432), (')', 6432), ('flight_1.flight_id', 4536), ('flight', 4221), ('SELECT', 4178)]\n",
      "\n",
      "Index for start of sequence token: 2\n",
      "Index for end of sequence token: 3\n"
     ]
    }
   ],
   "source": [
    " # Make splits for data\n",
    "train_data, val_data, test_data = tt.datasets.TranslationDataset.splits(\n",
    "    ('_flightid.nl', '_flightid.sql'), fields, path='./data/',\n",
    "    train='train', validation='dev', test='test')\n",
    "\n",
    "MIN_FREQ = 3\n",
    "SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
    "TGT.build_vocab(train_data.tgt, min_freq=MIN_FREQ)\n",
    "\n",
    "print (f\"Size of English vocab: {len(SRC.vocab)}\")\n",
    "print (f\"Most common English words: {SRC.vocab.freqs.most_common(10)}\\n\")\n",
    "\n",
    "print (f\"Size of SQL vocab: {len(TGT.vocab)}\")\n",
    "print (f\"Most common SQL words: {TGT.vocab.freqs.most_common(10)}\\n\")\n",
    "\n",
    "print (f\"Index for start of sequence token: {TGT.vocab.stoi[TGT.init_token]}\")\n",
    "print (f\"Index for end of sequence token: {TGT.vocab.stoi[TGT.eos_token]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23173189",
   "metadata": {},
   "source": [
    "Batch the data to facilitate processing on a GPU. sort_key function allows for sorting on length, to minimize the padding on the source side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e79df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # batch size for training/validation\n",
    "TEST_BATCH_SIZE = 1 # batch size for test, we use 1 to make beam search implementation easier\n",
    "\n",
    "train_iter, val_iter = tt.data.BucketIterator.splits((train_data, val_data),\n",
    "                                                     batch_size=BATCH_SIZE, \n",
    "                                                     device=device,\n",
    "                                                     repeat=False, \n",
    "                                                     sort_key=lambda x: len(x.src), \n",
    "                                                     sort_within_batch=True)\n",
    "test_iter = tt.data.BucketIterator(test_data, \n",
    "                                   batch_size=TEST_BATCH_SIZE, \n",
    "                                   device=device,\n",
    "                                   repeat=False, \n",
    "                                   sort=False, \n",
    "                                   train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44fa0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))\n",
    "train_batch_text, train_batch_text_lengths = batch.src\n",
    "train_batch_sql = batch.tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5af8b",
   "metadata": {},
   "source": [
    "Set up a SQL database to test the parses correctly return the right database entries using sqlite3 module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbe10c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql):\n",
    "  conn = sqlite3.connect('data/atis_sqlite.db')  # establish the DB based on the downloaded data\n",
    "  c = conn.cursor()                              # build a \"cursor\"\n",
    "  c.execute(sql)\n",
    "  results = list(c.fetchall())\n",
    "  c.close()\n",
    "  conn.close()\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae147fb",
   "metadata": {},
   "source": [
    "To run query, use execute function and retrieve results with fetchall. We can also build a parser with the augmented grammar. To interpret the tree, we recursively add the meanings of the child nodes until we have a completed tree representation to a semantic representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74d8f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(tree, augmentations):\n",
    "  syntactic_rule = tree.productions()[0]\n",
    "  semantic_rule = augmentations[syntactic_rule]\n",
    "  child_meanings = [interpret(child, augmentations) \n",
    "                    for child in tree \n",
    "                    if isinstance(child, nltk.Tree)]\n",
    "  return semantic_rule(*child_meanings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c6184",
   "metadata": {},
   "source": [
    "An example of a parse tree for a query is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb94cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flights', 'to', 'boston']\n",
      "                S                         \n",
      "                |                          \n",
      "            NP_FLIGHT                     \n",
      "                |                          \n",
      "            NOM_FLIGHT                    \n",
      "                |                          \n",
      "             N_FLIGHT                     \n",
      "      __________|_________                 \n",
      "     |                    PP              \n",
      "     |                    |                \n",
      "     |                 PP_PLACE           \n",
      "     |           _________|_________       \n",
      "  N_FLIGHT      |                N_PLACE  \n",
      "     |          |                   |      \n",
      "TERM_FLIGHT  P_PLACE            TERM_PLACE\n",
      "     |          |                   |      \n",
      "  flights       to                boston  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_tree(sentence):\n",
    "  \"\"\"Parse a sentence and return the parse tree, or None if failure.\"\"\"\n",
    "  try:\n",
    "    parses = list(atis_parser.parse(tokenize(sentence)))\n",
    "    if len(parses) == 0:\n",
    "      return None\n",
    "    else:\n",
    "      return parses[0]\n",
    "  except:\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "sample_query = \"flights to boston\"\n",
    "print(tokenize(sample_query))\n",
    "sample_tree = parse_tree(sample_query)\n",
    "sample_tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b8be4",
   "metadata": {},
   "source": [
    "Given a sentence, we first construct its parse tree using the syntactic rules, then compose the corresponding semantic rules bottom-up, until eventually we arrive at the root node with a finished SQL statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a3345e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted SQL:\n",
      "\n",
      " SELECT DISTINCT flight.flight_id FROM flight WHERE flight.to_airport IN \n",
      "    (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN\n",
      "      (SELECT city.city_code FROM city WHERE city.city_name = \"BOSTON\"))\n",
      "   AND 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "atis_grammar, atis_augmentations = xform.read_augmented_grammar('data/grammar', globals=globals())\n",
    "atis_parser = nltk.parse.BottomUpChartParser(atis_grammar)\n",
    "predicted_sql = interpret(sample_tree, atis_augmentations)\n",
    "\n",
    "# print out the predicted SQL from the grammar\n",
    "print(\"Predicted SQL:\\n\\n\", predicted_sql, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e43ed",
   "metadata": {},
   "source": [
    "We can create a function verify to compare the predicted SQL to the ground truth SQL from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e51c22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(predicted_sql, gold_sql, silent=True):\n",
    "  \"\"\"\n",
    "  Compare the correctness of the generated SQL by executing on the \n",
    "  ATIS database and comparing the returned results.\n",
    "  Arguments:\n",
    "      predicted_sql: the predicted SQL query\n",
    "      gold_sql: the reference SQL query to compare against\n",
    "      silent: print outputs or not\n",
    "  Returns: True if the returned results are the same, otherwise False\n",
    "  \"\"\"\n",
    "  # Execute predicted SQL\n",
    "  try:\n",
    "    predicted_result = execute_sql(predicted_sql)\n",
    "  except BaseException as e:\n",
    "    if not silent:\n",
    "      print(f\"predicted sql exec failed: {e}\")\n",
    "    return False\n",
    "  if not silent:\n",
    "    print(\"Predicted DB result:\\n\\n\", predicted_result[:10], \"\\n\")\n",
    "\n",
    "  # Execute gold SQL\n",
    "  try:\n",
    "    gold_result = execute_sql(gold_sql)\n",
    "  except BaseException as e:\n",
    "    if not silent:\n",
    "      print(f\"gold sql exec failed: {e}\")\n",
    "    return False\n",
    "  if not silent:\n",
    "    print(\"Gold DB result:\\n\\n\", gold_result[:10], \"\\n\")\n",
    "  \n",
    "  # Verify correctness\n",
    "  if gold_result == predicted_result:\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830dad7",
   "metadata": {},
   "source": [
    "We can make a simple checking function to see how accurate our parses are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e51439bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_trial(sentence, gold_sql):\n",
    "  print(\"Sentence: \", sentence, \"\\n\")\n",
    "  tree = parse_tree(sentence)\n",
    "  print(\"Parse:\\n\\n\")\n",
    "  tree.pretty_print()\n",
    "\n",
    "  predicted_sql = interpret(tree, atis_augmentations)\n",
    "  print(\"Predicted SQL:\\n\\n\", predicted_sql, \"\\n\")\n",
    "\n",
    "  if verify(predicted_sql, gold_sql, silent=False):\n",
    "    print ('Correct!')\n",
    "  else:\n",
    "    print ('Incorrect!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0e9ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  flights from phoenix to milwaukee \n",
      "\n",
      "Parse:\n",
      "\n",
      "\n",
      "                                  S                                 \n",
      "                                  |                                  \n",
      "                              NP_FLIGHT                             \n",
      "                                  |                                  \n",
      "                              NOM_FLIGHT                            \n",
      "                                  |                                  \n",
      "                               N_FLIGHT                             \n",
      "                __________________|_________________                 \n",
      "            N_FLIGHT                                |               \n",
      "      _________|________                            |                \n",
      "     |                  PP                          PP              \n",
      "     |                  |                           |                \n",
      "     |               PP_PLACE                    PP_PLACE           \n",
      "     |          ________|_________           _______|_________       \n",
      "  N_FLIGHT     |               N_PLACE      |              N_PLACE  \n",
      "     |         |                  |         |                 |      \n",
      "TERM_FLIGHT P_PLACE           TERM_PLACE P_PLACE          TERM_PLACE\n",
      "     |         |                  |         |                 |      \n",
      "  flights     from             phoenix      to            milwaukee \n",
      "\n",
      "Predicted SQL:\n",
      "\n",
      " SELECT DISTINCT flight.flight_id FROM flight WHERE flight.to_airport IN \n",
      "    (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN\n",
      "      (SELECT city.city_code FROM city WHERE city.city_name = \"MILWAUKEE\"))\n",
      "   AND flight.from_airport IN \n",
      "    (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN\n",
      "      (SELECT city.city_code FROM city WHERE city.city_name = \"PHOENIX\"))\n",
      "   AND 1 \n",
      "\n",
      "Predicted DB result:\n",
      "\n",
      " [(108086,), (108087,), (301763,), (301764,), (301765,), (301766,), (302323,), (304881,), (310619,), (310620,)] \n",
      "\n",
      "Gold DB result:\n",
      "\n",
      " [(108086,), (108087,), (301763,), (301764,), (301765,), (301766,), (302323,), (304881,), (310619,), (310620,)] \n",
      "\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "example_1 = 'flights from phoenix to milwaukee'\n",
    "gold_sql_1 = \"\"\"\n",
    "  SELECT DISTINCT flight_1.flight_id \n",
    "  FROM flight flight_1 , \n",
    "       airport_service airport_service_1 , \n",
    "       city city_1 , \n",
    "       airport_service airport_service_2 , \n",
    "       city city_2 \n",
    "  WHERE flight_1.from_airport = airport_service_1.airport_code \n",
    "        AND airport_service_1.city_code = city_1.city_code \n",
    "        AND city_1.city_name = 'PHOENIX' \n",
    "        AND flight_1.to_airport = airport_service_2.airport_code \n",
    "        AND airport_service_2.city_code = city_2.city_code \n",
    "        AND city_2.city_name = 'MILWAUKEE'\n",
    "  \"\"\"\n",
    "\n",
    "rule_based_trial(example_1, gold_sql_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1506c8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  i would like a united flight \n",
      "\n",
      "Parse:\n",
      "\n",
      "\n",
      "                                                 S                                                                      \n",
      "                                     ____________|____________________________________________________                   \n",
      "                                    |                                                             NP_FLIGHT             \n",
      "                                    |                                                                 |                  \n",
      "                                PREIGNORE                                                         NOM_FLIGHT            \n",
      "        ____________________________|____________                                          ___________|___________       \n",
      "       |                                     PREIGNORE                                   ADJ                      |     \n",
      "       |                _________________________|____________                            |                       |      \n",
      "       |               |                                  PREIGNORE                  ADJ_AIRLINE              NOM_FLIGHT\n",
      "       |               |                          ____________|____________               |                       |      \n",
      "       |               |                         |                     PREIGNORE     TERM_AIRLINE              N_FLIGHT \n",
      "       |               |                         |                         |              |                       |      \n",
      "PREIGNORESYMBOL PREIGNORESYMBOL           PREIGNORESYMBOL           PREIGNORESYMBOL TERM_AIRBRAND            TERM_FLIGHT\n",
      "       |               |                         |                         |              |                       |      \n",
      "       i             would                      like                       a            united                  flight  \n",
      "\n",
      "Predicted SQL:\n",
      "\n",
      " SELECT DISTINCT flight.flight_id FROM flight WHERE flight.airline_code = 'UA' AND 1 \n",
      "\n",
      "Predicted DB result:\n",
      "\n",
      " [(100094,), (100099,), (100145,), (100158,), (100164,), (100167,), (100169,), (100203,), (100204,), (100296,)] \n",
      "\n",
      "Gold DB result:\n",
      "\n",
      " [(100094,), (100099,), (100145,), (100158,), (100164,), (100167,), (100169,), (100203,), (100204,), (100296,)] \n",
      "\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "example_2 = 'i would like a united flight'\n",
    "gold_sql_2 = \"\"\"\n",
    "  SELECT DISTINCT flight_1.flight_id\n",
    "  FROM flight flight_1 \n",
    "  WHERE flight_1.airline_code = 'UA'\n",
    "  \"\"\"\n",
    "\n",
    "rule_based_trial(example_2, gold_sql_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab3526",
   "metadata": {},
   "source": [
    "Rather than one off checks, we can more systematically check our translation from natural language to SQL query with a function that checks for the precision, recall, and F1 of the predictions. It takes as an argument a predictor function that maps token sequences to predicted SQL queries. \n",
    "\n",
    "The augmented parser is not augmented to capture all sentences, only about a precision of 70% is expected, since not all sentences are able to be predicted in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c234e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictor, dataset, num_examples=0, silent=True):\n",
    "  \"\"\"Evaluate accuracy of `predictor` by executing predictions on a\n",
    "  SQL database and comparing returned results against those of gold queries.\n",
    "  \n",
    "  Arguments:\n",
    "      predictor:    a function that maps a token sequence (provided by torchtext)\n",
    "                    to a predicted SQL query string\n",
    "      dataset:      the dataset of token sequences and gold SQL queries\n",
    "      num_examples: number of examples from `dataset` to use; all of\n",
    "                    them if 0\n",
    "      silent: if set to False, will print out logs\n",
    "  Returns: precision, recall, and F1 score\n",
    "  \"\"\"\n",
    "  # Prepare to count results\n",
    "  if num_examples <= 0:\n",
    "    num_examples = len(dataset)\n",
    "  example_count = 0\n",
    "  predicted_count = 0\n",
    "  correct = 0\n",
    "  incorrect = 0\n",
    "\n",
    "  # Process the examples from the dataset\n",
    "  for example in tqdm(dataset[:num_examples]):\n",
    "    example_count += 1\n",
    "    # obtain query SQL\n",
    "    predicted_sql = predictor(example.src)\n",
    "    if predicted_sql == None:\n",
    "      continue\n",
    "    predicted_count += 1\n",
    "    # obtain gold SQL\n",
    "    gold_sql = ' '.join(example.tgt)\n",
    "\n",
    "    # check that they're compatible\n",
    "    if verify(predicted_sql, gold_sql):\n",
    "      correct += 1\n",
    "    else:\n",
    "      incorrect += 1\n",
    "   \n",
    "  # Compute and return precision, recall, F1\n",
    "  precision = correct / predicted_count if predicted_count > 0 else 0\n",
    "  recall = correct / example_count\n",
    "  f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "  return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20692d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_predictor(tokens):\n",
    "  query = ' '.join(tokens)    # detokenized query\n",
    "  tree = parse_tree(query)\n",
    "  if tree is None:\n",
    "    return None\n",
    "  try:\n",
    "    predicted_sql = interpret(tree, atis_augmentations)\n",
    "  except Exception as err:\n",
    "    return None\n",
    "  return predicted_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f4fca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 332/332 [00:02<00:00, 138.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.73\n",
      "recall:    0.27\n",
      "F1:        0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = evaluate(rule_based_predictor, test_iter.dataset, num_examples=0)\n",
    "print(f\"precision: {precision:3.2f}\")\n",
    "print(f\"recall:    {recall:3.2f}\")\n",
    "print(f\"F1:        {f1:3.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c883212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
